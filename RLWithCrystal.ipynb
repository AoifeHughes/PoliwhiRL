{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: Using SDL2 binaries from pysdl2-dll 2.28.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "from itertools import count\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import os\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyboy import PyBoy, WindowEvent # isort:skip\n",
    "\n",
    "rom_path = 'Pokemon - Crystal Version.gbc'\n",
    "screen_size = (160, 144)\n",
    "\n",
    "# Create the images folder if it doesn't exist\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_IMG = True\n",
    "\n",
    "def start_pyboy():\n",
    "    pyboy = PyBoy(rom_path,  window_scale=1)\n",
    "    pyboy.set_emulation_speed(target_speed=0)\n",
    "    return pyboy\n",
    "\n",
    "pyboy=start_pyboy()\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    # Convert the PIL image to grayscale\n",
    "    gray = image.convert('L')\n",
    "\n",
    "    # Enhance the image contrast\n",
    "    enhancer = ImageEnhance.Contrast(gray)\n",
    "    enhanced_image = enhancer.enhance(2)\n",
    "\n",
    "    # Apply thresholding to make the image binary\n",
    "    threshold = 127\n",
    "    binary_image = enhanced_image.point(lambda p: p > threshold and 255)\n",
    "\n",
    "    # Extracting text using pytesseract\n",
    "    text = pytesseract.image_to_string(binary_image, config='--psm 6')\n",
    "\n",
    "    return text\n",
    "\n",
    "movements = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\", \"A\", \"B\", \"START\", \"SELECT\"]\n",
    "\n",
    "def pyBoyHandleMovement(movement):\n",
    "    if movement == \"UP\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_ARROW_UP)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_ARROW_UP)\n",
    "    elif movement == \"DOWN\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_ARROW_DOWN)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_ARROW_DOWN)\n",
    "    elif movement == \"LEFT\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_ARROW_LEFT)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_ARROW_LEFT)\n",
    "    elif movement == \"RIGHT\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_ARROW_RIGHT)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_ARROW_RIGHT)\n",
    "    elif movement == \"A\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_BUTTON_A)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_BUTTON_A)\n",
    "    elif movement == \"B\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_BUTTON_B)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_BUTTON_B)\n",
    "    elif movement == \"START\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_BUTTON_START)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_BUTTON_START)\n",
    "    elif movement == \"SELECT\":\n",
    "        pyboy.send_input(WindowEvent.PRESS_BUTTON_SELECT)\n",
    "        pyboy.tick()\n",
    "        pyboy.send_input(WindowEvent.RELEASE_BUTTON_SELECT)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found at 'pokemon_rl_checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s][E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:110] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "  0%|          | 0/100 [00:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 178\u001b[0m\n\u001b[1;32m    175\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(state, action, reward, next_state)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Perform optimization step\u001b[39;00m\n\u001b[0;32m--> 178\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# Move to the next state\u001b[39;00m\n\u001b[1;32m    181\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "Cell \u001b[0;32mIn[3], line 131\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[1;32m    133\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mgba/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mgba/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the neural network\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)  \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Compute the output size of the conv layers dynamically\n",
    "        self._to_linear = None\n",
    "        self._compute_conv_output_size(h, w)\n",
    "\n",
    "        self.fc = nn.Linear(8160, outputs)\n",
    "\n",
    "    def _compute_conv_output_size(self, h, w):\n",
    "        # Temporary tensor to compute output size\n",
    "        x = torch.rand(1, 3, h, w)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        self._to_linear = x.view(1, -1).size(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "\n",
    "        return self.fc(x)\n",
    "\n",
    "# Replay Memory\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(args)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "\n",
    "\n",
    "# Path to save or load the checkpoint\n",
    "checkpoint_path = \"pokemon_rl_checkpoint.pth\"\n",
    "\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "num_actions = len(movements)  # Define movements somewhere in your code\n",
    "input_shape = (160, 140, 3)  # RGB images\n",
    "model = DQN(input_shape[0], input_shape[1], num_actions)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename=checkpoint_path):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "# Function to load a checkpoint\n",
    "def load_checkpoint():\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print(f\"Loading checkpoint '{checkpoint_path}'\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        start_episode = checkpoint['epoch']\n",
    "        epsilon = checkpoint['epsilon']\n",
    "        return start_episode, epsilon\n",
    "    else:\n",
    "        print(f\"No checkpoint found at '{checkpoint_path}'\")\n",
    "        return 0, 0.9  # Return default values for start_episode and epsilon\n",
    "\n",
    "\n",
    "\n",
    "# Function to choose an action\n",
    "epsilon = 0.9  # Make sure to decay epsilon over time\n",
    "start_episode, epsilon = load_checkpoint()\n",
    "\n",
    "def select_action(state):\n",
    "    global epsilon\n",
    "    if random.random() > epsilon:\n",
    "        with torch.no_grad():\n",
    "            return model(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(num_actions)]], dtype=torch.long)\n",
    "\n",
    "# Function to convert the emulator image to a tensor\n",
    "def image_to_tensor(image):\n",
    "    # Convert image to PyTorch tensor\n",
    "    image = np.array(image)\n",
    "    image = torch.from_numpy(image).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    image = image.to(torch.float32) / 255  # Normalize the input\n",
    "    return image\n",
    "\n",
    "# Optimization function\n",
    "def optimize_model(batch_size=128):\n",
    "    if len(memory) < batch_size:\n",
    "        return\n",
    "    transitions = memory.sample(batch_size)\n",
    "    batch = tuple(zip(*transitions))\n",
    "\n",
    "    # Extract tensors from batch\n",
    "    state_batch = torch.cat(batch[0])\n",
    "    action_batch = torch.cat(batch[1])\n",
    "    reward_batch = torch.cat(batch[2])\n",
    "\n",
    "    # Compute Q(s_t, a)\n",
    "    state_action_values = model(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states\n",
    "    next_state_values = torch.zeros(batch_size)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch[3])), dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch[3] if s is not None])\n",
    "    next_state_values[non_final_mask] = model(non_final_next_states).max(1)[0].detach()\n",
    "\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * 0.99) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in model.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "num_episodes = 100\n",
    "for i_episode in tqdm(range(start_episode, num_episodes+start_episode)):\n",
    "    # Initialize the environment and state\n",
    "    pyboy.stop(save=False)\n",
    "    pyboy= start_pyboy()\n",
    "    state = image_to_tensor(pyboy.screen_image())\n",
    "\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        pyBoyHandleMovement(movements[action.item()])\n",
    "        reward = torch.tensor([-0.01], dtype=torch.float32)  # Small negative reward for each step\n",
    "\n",
    "        # Check if the goal is achieved\n",
    "        if 'neighbor' in extract_text_from_image(pyboy.screen_image()):\n",
    "            reward = torch.tensor([1.0], dtype=torch.float32)\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        # Observe new state\n",
    "        img = pyboy.screen_image()\n",
    "        # if SAVE_IMG:\n",
    "        #     # Create images folder for this run if it doesn't exist\n",
    "        #     if not os.path.exists(f'images/{i_episode}'):\n",
    "        #         os.makedirs(f'images/{i_episode}')\n",
    "            \n",
    "        #     # Save image using PIL\n",
    "        #     print(f\"Saving image {t} for episode {i_episode}\")\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        # Update the existing imshow window \n",
    "\n",
    "        next_state = image_to_tensor(img) if not done else None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, reward, next_state)\n",
    "\n",
    "        # Perform optimization step\n",
    "        optimize_model()\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(f\"Episode {i_episode} finished after {t+1} steps\")\n",
    "            break\n",
    "\n",
    "    # Decrease epsilon\n",
    "    epsilon = max(epsilon * 0.99, 0.05)\n",
    "   \n",
    "    # Save checkpoint every 10 episodes\n",
    "    if i_episode % 10 == 0:\n",
    "        save_checkpoint({\n",
    "            'epoch': i_episode + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epsilon': epsilon\n",
    "        })\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"pokemon_rl_model_final.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
