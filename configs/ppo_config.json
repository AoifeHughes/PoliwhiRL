{
    "model": "PPO",
    "episode_length": 1000,
    "num_episodes": 1000,
    "device": "mps",
    "n_steps": 1,
    "checkpoint_interval": 500,
    "scaling_factor": 1,
    "use_grayscale": false,
    "extend_on_reward": false,
    "erase": false,
    "reward_image_folder": "./configs/reward_images",
    "sequence_length": 10,
    "eval_episodes": 1,
    "checkpoint": "./configs/checkpoints/",
    "update_timestep": 200
  }
