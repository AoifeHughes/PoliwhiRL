{
  "rom_path": "./emu_files/Pokemon - Crystal Version.gbc",
  "state_path": "./emu_files/states/start.state",
  "episode_length": 20000,
  "device": "mps",
  "use_curriculum": false,
  "num_episodes": 250,
  "num_agents": 5,
  "batch_size": 64,
  "checkpoint": "./Training Outputs/Checkpoints",
  "model": "PPO",
  "erase": false,
  "gamma": 0.99,
  "scaling_factor": 0.5,
  "extra_files": [
    "./emu_files/Pokemon - Crystal Version.gbc.ram",
    "./emu_files/Pokemon - Crystal Version.gbc.rtc"
  ],
  "location_goals": [
    [[9, 1, 6, 50]],
    [[8, 4, 6, 50], [9, 4, 6, 50]],
    [[8, 5, 6, 50], [9, 5, 6, 50]],
    [[13, 6, 4, 50]],
    [[6, 4, 4, 50]],
    [[59, 8, 3, 50], [59, 9, 3, 50]],
    [[31, 13, 3, 50]]
  ],
  "pokedex_goals": {
    "owned": 1,
    "seen": 2
  },
  "early_stopping_avg_length": 500,
  "use_grayscale": false,
  "intrinsic_reward_scale": 0.01,
  "learning_rate": 1e-3,
  "use_curiosity": false,
  "vision": true,
  "N_goals_target": 6,
  "epochs": 1,
  "max_temperature": 2.0,
  "min_temperature": 0.01,
  "temperature_cycle_length": 100,
  "target_update_frequency": 50,
  "replay_buffer_capacity": 500,
  "sequence_length": 16,
  "update_frequency": 512,
  "record_frequency": 10,
  "results_dir": "./Training Outputs/Results",
  "db_path": "./Training Outputs/Database/memory.db",
  "record_path": "./Training Outputs/Runs",
  "record": true,
  "break_on_goal": true,
  "verbose": false,
  "ignored_buttons": ["", "start", "select"],
  "manual_control": false,
  "explore_db_loc": "./Training Outputs/Database/explore.db",
  "export_state_loc": "./Training Outputs/Training States",
  "continue_from_state": false,
  "continue_from_state_loc": "./Training Outputs/Training States/state.pkl",
  "num_random_episodes": 25,
  "ppo_epsilon": 0.2,
  "ppo_epochs": 4,
  "curiosity_weight": 0.01,
  "value_loss_coef": 0.5,
  "entropy_coef": 0.1,
  "entropy_coef_decay": 0.9999,
  "entropy_coef_min": 0.01,
  "icm_loss_scale": 0.1,
  "lr_scheduler_patience": 50,
  "lr_scheduler_factor": 0.7,
  "lr_scheduler_min_lr": 1e-5,
  "lr_scheduler_threshold": 0.01,
  "extrinsic_reward_weight": 1.0,
  "intrinsic_reward_weight": 0.01,
  "n_steps": 5,
  "punish_steps": false
}